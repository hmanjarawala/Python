{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himanshu.manjarawala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\himanshu.manjarawala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.testing import all_estimators\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, r2_score, mean_squared_error\n",
    "import warnings\n",
    "import xgboost\n",
    "# import catboost\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "pd.set_option(\"display.float_format\", lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "\n",
    "removed_classifiers = [('ComplementNB', sklearn.naive_bayes.ComplementNB),\n",
    " ('GradientBoostingClassifier',\n",
    "  sklearn.ensemble.gradient_boosting.GradientBoostingClassifier),\n",
    " ('GaussianProcessClassifier',sklearn.gaussian_process.gpc.GaussianProcessClassifier),\n",
    " ('MLPClassifier', sklearn.neural_network.multilayer_perceptron.MLPClassifier),\n",
    " ('LogisticRegressionCV', sklearn.linear_model.logistic.LogisticRegressionCV),\n",
    " ('MultinomialNB', sklearn.naive_bayes.MultinomialNB),\n",
    " ('RadiusNeighborsClassifier',\n",
    "  sklearn.neighbors.classification.RadiusNeighborsClassifier)]\n",
    "\n",
    "for i in removed_classifiers:\n",
    "    CLASSIFIERS.pop(CLASSIFIERS.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSORS = [est for est in all_estimators() if issubclass(est[1], RegressorMixin)]\n",
    "\n",
    "removed_regressors = [('TheilSenRegressor', sklearn.linear_model.theil_sen.TheilSenRegressor),\n",
    " ('ARDRegression', sklearn.linear_model.ARDRegression),\n",
    " ('CCA', sklearn.cross_decomposition.CCA),\n",
    " ('MultiTaskElasticNet',\n",
    "  sklearn.linear_model.MultiTaskElasticNet),\n",
    " ('MultiTaskElasticNetCV',\n",
    "  sklearn.linear_model.MultiTaskElasticNetCV),\n",
    " ('MultiTaskLasso', sklearn.linear_model.MultiTaskLasso),\n",
    " ('MultiTaskLassoCV',\n",
    "  sklearn.linear_model.MultiTaskLassoCV),\n",
    " ('PLSCanonical', sklearn.cross_decomposition.PLSCanonical),\n",
    " ('PLSRegression', sklearn.cross_decomposition.PLSRegression),\n",
    " ('RadiusNeighborsRegressor',\n",
    "  sklearn.neighbors.RadiusNeighborsRegressor)]\n",
    "\n",
    "for i in removed_regressors:\n",
    "    REGRESSORS.pop(REGRESSORS.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSORS.append(('XGBRegressor', xgboost.XGBRegressor))\n",
    "REGRESSORS.append(('LGBMRegressor',lightgbm.LGBMRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS.append(('XGBClassifier',xgboost.XGBClassifier))\n",
    "CLASSIFIERS.append(('LGBMClassifier',lightgbm.LGBMClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_low = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoding', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "categorical_transformer_high = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    # 'OrdianlEncoder' Raise a ValueError when encounters an unknown value. Check https://github.com/scikit-learn/scikit-learn/pull/13423\n",
    "    ('encoding', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def get_card_split(df, cols, n=11):\n",
    "    \"\"\"\n",
    "    Splits categorical columns into 2 lists based on cardinality (i.e # of unique values)\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which the cardinality of the columns is calculated.\n",
    "    cols : list-like\n",
    "        Categorical columns to list\n",
    "    n : int, optional (default=11)\n",
    "        The value of 'n' will be used to split columns.\n",
    "    Returns\n",
    "    -------\n",
    "    card_low : list-like\n",
    "        Columns with cardinality < n\n",
    "    card_high : list-like\n",
    "        Columns with cardinality >= n\n",
    "    \"\"\"\n",
    "    cond = df[cols].nunique() > n\n",
    "    card_high = cols[cond]\n",
    "    card_low  = cols[~cond]\n",
    "    return card_low, card_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for performing classification\n",
    "\n",
    "class LazyClassifier:\n",
    "    \"\"\"\n",
    "    This module helps in fitting to all the classification algorithms that are available in Scikit-learn\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : int, optional (default=0)\n",
    "        For the liblinear and lbfgs solvers set verbose to any positive\n",
    "        number for verbosity.\n",
    "    ignore_warnings : bool, optional (default=True)\n",
    "        When set to True, the warning related to algorigms that are not able to run are ignored.\n",
    "    custom_metric : function, optional (default=None)\n",
    "        When function is provided, models are evaluated based on the custom evaluation metric provided.\n",
    "    prediction : bool, optional (default=False)\n",
    "        When set to True, the predictions of all the models models are returned as dataframe.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from lazypredict.Supervised import LazyClassifier\n",
    "    >>> from sklearn.datasets import load_breast_cancer\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>> data = load_breast_cancer()\n",
    "    >>> X = data.data\n",
    "    >>> y= data.target\n",
    "    >>> X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "    >>> clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    >>> models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "    >>> models\n",
    "    | Model                          |   Accuracy |   Balanced Accuracy |   ROC AUC |   F1 Score |   Time Taken |\n",
    "    |:-------------------------------|-----------:|--------------------:|----------:|-----------:|-------------:|\n",
    "    | LinearSVC                      |   0.989474 |            0.987544 |  0.987544 |   0.989462 |    0.0150008 |\n",
    "    | SGDClassifier                  |   0.989474 |            0.987544 |  0.987544 |   0.989462 |    0.0109992 |\n",
    "    | MLPClassifier                  |   0.985965 |            0.986904 |  0.986904 |   0.985994 |    0.426     |\n",
    "    | Perceptron                     |   0.985965 |            0.984797 |  0.984797 |   0.985965 |    0.0120046 |\n",
    "    | LogisticRegression             |   0.985965 |            0.98269  |  0.98269  |   0.985934 |    0.0200036 |\n",
    "    | LogisticRegressionCV           |   0.985965 |            0.98269  |  0.98269  |   0.985934 |    0.262997  |\n",
    "    | SVC                            |   0.982456 |            0.979942 |  0.979942 |   0.982437 |    0.0140011 |\n",
    "    | CalibratedClassifierCV         |   0.982456 |            0.975728 |  0.975728 |   0.982357 |    0.0350015 |\n",
    "    | PassiveAggressiveClassifier    |   0.975439 |            0.974448 |  0.974448 |   0.975464 |    0.0130005 |\n",
    "    | LabelPropagation               |   0.975439 |            0.974448 |  0.974448 |   0.975464 |    0.0429988 |\n",
    "    | LabelSpreading                 |   0.975439 |            0.974448 |  0.974448 |   0.975464 |    0.0310006 |\n",
    "    | RandomForestClassifier         |   0.97193  |            0.969594 |  0.969594 |   0.97193  |    0.033     |\n",
    "    | GradientBoostingClassifier     |   0.97193  |            0.967486 |  0.967486 |   0.971869 |    0.166998  |\n",
    "    | QuadraticDiscriminantAnalysis  |   0.964912 |            0.966206 |  0.966206 |   0.965052 |    0.0119994 |\n",
    "    | HistGradientBoostingClassifier |   0.968421 |            0.964739 |  0.964739 |   0.968387 |    0.682003  |\n",
    "    | RidgeClassifierCV              |   0.97193  |            0.963272 |  0.963272 |   0.971736 |    0.0130029 |\n",
    "    | RidgeClassifier                |   0.968421 |            0.960525 |  0.960525 |   0.968242 |    0.0119977 |\n",
    "    | AdaBoostClassifier             |   0.961404 |            0.959245 |  0.959245 |   0.961444 |    0.204998  |\n",
    "    | ExtraTreesClassifier           |   0.961404 |            0.957138 |  0.957138 |   0.961362 |    0.0270066 |\n",
    "    | KNeighborsClassifier           |   0.961404 |            0.95503  |  0.95503  |   0.961276 |    0.0560005 |\n",
    "    | BaggingClassifier              |   0.947368 |            0.954577 |  0.954577 |   0.947882 |    0.0559971 |\n",
    "    | BernoulliNB                    |   0.950877 |            0.951003 |  0.951003 |   0.951072 |    0.0169988 |\n",
    "    | LinearDiscriminantAnalysis     |   0.961404 |            0.950816 |  0.950816 |   0.961089 |    0.0199995 |\n",
    "    | GaussianNB                     |   0.954386 |            0.949536 |  0.949536 |   0.954337 |    0.0139935 |\n",
    "    | NuSVC                          |   0.954386 |            0.943215 |  0.943215 |   0.954014 |    0.019989  |\n",
    "    | DecisionTreeClassifier         |   0.936842 |            0.933693 |  0.933693 |   0.936971 |    0.0170023 |\n",
    "    | NearestCentroid                |   0.947368 |            0.933506 |  0.933506 |   0.946801 |    0.0160074 |\n",
    "    | ExtraTreeClassifier            |   0.922807 |            0.912168 |  0.912168 |   0.922462 |    0.0109999 |\n",
    "    | CheckingClassifier             |   0.361404 |            0.5      |  0.5      |   0.191879 |    0.0170043 |\n",
    "    | DummyClassifier                |   0.512281 |            0.489598 |  0.489598 |   0.518924 |    0.0119965 |\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0, ignore_warnings=True, custom_metric = None, predictions = False,random_state=42):\n",
    "        self.verbose = verbose\n",
    "        self.ignore_warnings = ignore_warnings\n",
    "        self.custom_metric = custom_metric\n",
    "        self.predictions = predictions\n",
    "        self.random_state =random_state\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Fit Classification algorithms to X_train and y_train, predict and score on X_test, y_test.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        scores : Pandas DataFrame\n",
    "            Returns metrics of all the models in a Pandas DataFrame.\n",
    "        predictions : Pandas DataFrame\n",
    "            Returns predictions of all the models in a Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        Accuracy = []\n",
    "        B_Accuracy = []\n",
    "        ROC_AUC = []\n",
    "        F1 = []\n",
    "        names = []\n",
    "        TIME = []\n",
    "        predictions = {}\n",
    "        \n",
    "        if self.custom_metric != None:\n",
    "            CUSTOM_METRIC = []\n",
    "            \n",
    "        if type(X_train) is np.ndarray:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "        categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        lst_transformer = []\n",
    "        \n",
    "        if(len(numeric_features)>0):\n",
    "            lst_transformer.append(('numeric', numeric_transformer, numeric_features))\n",
    "        \n",
    "        if(len(categorical_features)>0):\n",
    "            categorical_low, categorical_high = get_card_split(X_train, categorical_features)\n",
    "            lst_transformer.append([\n",
    "                ('categorical_low', categorical_transformer_low, categorical_low),\n",
    "                ('categorical_high', categorical_transformer_high, categorical_high)\n",
    "            ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=lst_transformer)\n",
    "\n",
    "        for name, model in tqdm(CLASSIFIERS):\n",
    "            start = time.time()\n",
    "            try:\n",
    "                if 'random_state' in model().get_params().keys():\n",
    "                    pipe = Pipeline(steps=[\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('classifier', model(random_state = self.random_state))\n",
    "                    ])\n",
    "                else:\n",
    "                    pipe = Pipeline(steps=[\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('classifier', model())\n",
    "                    ])\n",
    "\n",
    "                pipe.fit(X_train, y_train)\n",
    "                y_pred = pipe.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "                b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                except Exception as exception:\n",
    "                    roc_auc = None\n",
    "                    if self.ignore_warnings == False:\n",
    "                        print(\"ROC AUC couldn't be calculated for \"+name)\n",
    "                        print(exception)\n",
    "                names.append(name)\n",
    "                Accuracy.append(accuracy)\n",
    "                B_Accuracy.append(b_accuracy)\n",
    "                ROC_AUC.append(roc_auc)\n",
    "                F1.append(f1)\n",
    "                TIME.append(time.time() - start)\n",
    "                if self.custom_metric != None:\n",
    "                    custom_metric = self.custom_metric(y_test, y_pred)\n",
    "                    CUSTOM_METRIC.append(custom_metric)\n",
    "                if self.verbose > 0:\n",
    "                    if self.custom_metric != None:\n",
    "                        print({\"Model\": name,\n",
    "                               \"Accuracy\": accuracy,\n",
    "                               \"Balanced Accuracy\": b_accuracy,\n",
    "                               \"ROC AUC\": roc_auc,\n",
    "                               \"F1 Score\": f1,\n",
    "                               self.custom_metric.__name__: custom_metric,\n",
    "                              \"Time taken\": time.time() - start})\n",
    "                    else:\n",
    "                        print({\"Model\": name,\n",
    "                               \"Accuracy\": accuracy,\n",
    "                               \"Balanced Accuracy\": b_accuracy,\n",
    "                               \"ROC AUC\": roc_auc,\n",
    "                               \"F1 Score\": f1,\n",
    "                              \"Time taken\": time.time() - start})\n",
    "                if self.predictions == True:\n",
    "                    predictions[name]=y_pred\n",
    "            except Exception as exception:\n",
    "                if self.ignore_warnings == False:\n",
    "                    print(name + \" model failed to execute\")\n",
    "                    print(exception)\n",
    "        if self.custom_metric == None:\n",
    "            scores = pd.DataFrame({\"Model\": names,\n",
    "                                   \"Accuracy\": Accuracy,\n",
    "                                   \"Balanced Accuracy\": B_Accuracy,\n",
    "                                   \"ROC AUC\": ROC_AUC,\n",
    "                                   \"F1 Score\": F1,\n",
    "                                   \"Time Taken\": TIME})\n",
    "        else:\n",
    "            scores = pd.DataFrame({\"Model\": names,\n",
    "                                   \"Accuracy\": Accuracy,\n",
    "                                   \"Balanced Accuracy\": B_Accuracy,\n",
    "                                   \"ROC AUC\": ROC_AUC,\n",
    "                                   \"F1 Score\": F1,\n",
    "                                  self.custom_metric.__name__: CUSTOM_METRIC,\n",
    "                                  \"Time Taken\": TIME})\n",
    "        scores = scores.sort_values(\n",
    "            by='Balanced Accuracy', ascending=False).set_index('Model')\n",
    "\n",
    "        if self.predictions == True:\n",
    "            predictions_df = pd.DataFrame.from_dict(predictions)\n",
    "        return scores, predictions_df if self.predictions == True else scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for performing Regression\n",
    "\n",
    "\n",
    "class LazyRegressor:\n",
    "    \"\"\"\n",
    "    This module helps in fitting regression models that are available in Scikit-learn\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : int, optional (default=0)\n",
    "        For the liblinear and lbfgs solvers set verbose to any positive\n",
    "        number for verbosity.\n",
    "    ignore_warnings : bool, optional (default=True)\n",
    "        When set to True, the warning related to algorigms that are not able to run are ignored.\n",
    "    custom_metric : function, optional (default=None)\n",
    "        When function is provided, models are evaluated based on the custom evaluation metric provided.\n",
    "    prediction : bool, optional (default=False)\n",
    "        When set to True, the predictions of all the models models are returned as dataframe.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from lazypredict.Supervised import LazyRegressor\n",
    "    >>> from sklearn import datasets\n",
    "    >>> from sklearn.utils import shuffle\n",
    "    >>> import numpy as np\n",
    "    >>> boston = datasets.load_boston()\n",
    "    >>> X, y = shuffle(boston.data, boston.target, random_state=13)\n",
    "    >>> X = X.astype(np.float32)\n",
    "    >>> offset = int(X.shape[0] * 0.9)\n",
    "    >>> X_train, y_train = X[:offset], y[:offset]\n",
    "    >>> X_test, y_test = X[offset:], y[offset:]\n",
    "    >>> reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
    "    >>> models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    | Model                         |   R-Squared |     RMSE |   Time Taken |\n",
    "    |:------------------------------|------------:|---------:|-------------:|\n",
    "    | SVR                           |   0.877199  |  2.62054 |    0.0330021 |\n",
    "    | RandomForestRegressor         |   0.874429  |  2.64993 |    0.0659981 |\n",
    "    | ExtraTreesRegressor           |   0.867566  |  2.72138 |    0.0570002 |\n",
    "    | AdaBoostRegressor             |   0.865851  |  2.73895 |    0.144999  |\n",
    "    | NuSVR                         |   0.863712  |  2.7607  |    0.0340044 |\n",
    "    | GradientBoostingRegressor     |   0.858693  |  2.81107 |    0.13      |\n",
    "    | KNeighborsRegressor           |   0.826307  |  3.1166  |    0.0179954 |\n",
    "    | HistGradientBoostingRegressor |   0.810479  |  3.25551 |    0.820995  |\n",
    "    | BaggingRegressor              |   0.800056  |  3.34383 |    0.0579946 |\n",
    "    | MLPRegressor                  |   0.750536  |  3.73503 |    0.725997  |\n",
    "    | HuberRegressor                |   0.736973  |  3.83522 |    0.0370018 |\n",
    "    | LinearSVR                     |   0.71914   |  3.9631  |    0.0179989 |\n",
    "    | RidgeCV                       |   0.718402  |  3.9683  |    0.018003  |\n",
    "    | BayesianRidge                 |   0.718102  |  3.97041 |    0.0159984 |\n",
    "    | Ridge                         |   0.71765   |  3.9736  |    0.0149941 |\n",
    "    | LinearRegression              |   0.71753   |  3.97444 |    0.0190051 |\n",
    "    | TransformedTargetRegressor    |   0.71753   |  3.97444 |    0.012001  |\n",
    "    | LassoCV                       |   0.717337  |  3.9758  |    0.0960066 |\n",
    "    | ElasticNetCV                  |   0.717104  |  3.97744 |    0.0860076 |\n",
    "    | LassoLarsCV                   |   0.717045  |  3.97786 |    0.0490005 |\n",
    "    | LassoLarsIC                   |   0.716636  |  3.98073 |    0.0210001 |\n",
    "    | LarsCV                        |   0.715031  |  3.99199 |    0.0450008 |\n",
    "    | Lars                          |   0.715031  |  3.99199 |    0.0269964 |\n",
    "    | SGDRegressor                  |   0.714362  |  3.99667 |    0.0210009 |\n",
    "    | RANSACRegressor               |   0.707849  |  4.04198 |    0.111998  |\n",
    "    | ElasticNet                    |   0.690408  |  4.16088 |    0.0190012 |\n",
    "    | Lasso                         |   0.662141  |  4.34668 |    0.0180018 |\n",
    "    | OrthogonalMatchingPursuitCV   |   0.591632  |  4.77877 |    0.0180008 |\n",
    "    | ExtraTreeRegressor            |   0.583314  |  4.82719 |    0.0129974 |\n",
    "    | PassiveAggressiveRegressor    |   0.556668  |  4.97914 |    0.0150032 |\n",
    "    | GaussianProcessRegressor      |   0.428298  |  5.65425 |    0.0580051 |\n",
    "    | OrthogonalMatchingPursuit     |   0.379295  |  5.89159 |    0.0180039 |\n",
    "    | DecisionTreeRegressor         |   0.318767  |  6.17217 |    0.0230272 |\n",
    "    | DummyRegressor                |  -0.0215752 |  7.55832 |    0.0140116 |\n",
    "    | LassoLars                     |  -0.0215752 |  7.55832 |    0.0180008 |\n",
    "    | KernelRidge                   |  -8.24669   | 22.7396  |    0.0309792 |\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0, ignore_warnings=True, custom_metric = None, predictions = False,random_state=42):\n",
    "        self.verbose = verbose\n",
    "        self.ignore_warnings = ignore_warnings\n",
    "        self.custom_metric = custom_metric\n",
    "        self.predictions = predictions\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Fit Regression algorithms to X_train and y_train, predict and score on X_test, y_test.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        scores : Pandas DataFrame\n",
    "            Returns metrics of all the models in a Pandas DataFrame.\n",
    "        predictions : Pandas DataFrame\n",
    "            Returns predictions of all the models in a Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        R2 = []\n",
    "        RMSE = []\n",
    "        # WIN = []\n",
    "        names = []\n",
    "        TIME = []\n",
    "        predictions = {}\n",
    "        \n",
    "        if self.custom_metric != None:\n",
    "            CUSTOM_METRIC = []\n",
    "\n",
    "        if type(X_train) is np.ndarray:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "        categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        lst_transformer = []\n",
    "        \n",
    "        if(len(numeric_features)>0):\n",
    "            lst_transformer.append(('numeric', numeric_transformer, numeric_features))\n",
    "        \n",
    "        if(len(categorical_features)>0):\n",
    "            categorical_low, categorical_high = get_card_split(X_train, categorical_features)\n",
    "            lst_transformer.append([\n",
    "                ('categorical_low', categorical_transformer_low, categorical_low),\n",
    "                ('categorical_high', categorical_transformer_high, categorical_high)\n",
    "            ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=lst_transformer)\n",
    "\n",
    "        for name, model in tqdm(REGRESSORS):\n",
    "            start = time.time()\n",
    "            try:\n",
    "                if 'random_state' in model().get_params().keys():\n",
    "                    pipe = Pipeline(steps=[\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('regressor', model(random_state = self.random_state))\n",
    "                    ])\n",
    "                else:\n",
    "                    pipe = Pipeline(steps=[\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('regressor', model())\n",
    "                ])\n",
    "                pipe.fit(X_train, y_train)\n",
    "                y_pred = pipe.predict(X_test)\n",
    "                r_squared = r2_score(y_test, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                names.append(name)\n",
    "                R2.append(r_squared)\n",
    "                RMSE.append(rmse)\n",
    "                TIME.append(time.time() - start)\n",
    "                if self.custom_metric != None:\n",
    "                    custom_metric = self.custom_metric(y_test, y_pred)\n",
    "                    CUSTOM_METRIC.append(custom_metric)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    if self.custom_metric != None:\n",
    "                        print({\"Model\": name,\n",
    "                               \"R-Squared\": r_squared,\n",
    "                               \"RMSE\": rmse,\n",
    "                               self.custom_metric.__name__: custom_metric,\n",
    "                              \"Time taken\": time.time() - start})\n",
    "                    else:\n",
    "                        print({\"Model\": name,\n",
    "                               \"R-Squared\": r_squared,\n",
    "                               \"RMSE\": rmse,\n",
    "                              \"Time taken\": time.time() - start})\n",
    "                if self.predictions == True:\n",
    "                    predictions[name]=y_pred\n",
    "            except Exception as exception:\n",
    "                if self.ignore_warnings == False:\n",
    "                    print(name + \" model failed to execute\")\n",
    "                    print(exception)\n",
    "                    \n",
    "        if self.custom_metric == None:\n",
    "            scores = pd.DataFrame({\"Model\": names, \n",
    "                                   \"R-Squared\": R2, \n",
    "                                   \"RMSE\": RMSE,\n",
    "                                   \"Time Taken\": TIME})\n",
    "        else:\n",
    "            scores = pd.DataFrame({\"Model\": names, \n",
    "                                   \"R-Squared\": R2, \n",
    "                                   \"RMSE\": RMSE,\n",
    "                                  self.custom_metric.__name__: CUSTOM_METRIC,\n",
    "                                  \"Time Taken\": TIME})\n",
    "        scores = scores.sort_values(\n",
    "            by='R-Squared', ascending=False).set_index('Model')\n",
    "        \n",
    "        if self.predictions == True:\n",
    "            predictions_df = pd.DataFrame.from_dict(predictions)\n",
    "        return scores, predictions_df if self.predictions == True else scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression = LazyRegressor\n",
    "Classification = LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
